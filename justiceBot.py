# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G7ja2skk9Ib03Nogj542E4k6JyBC9BaY
"""

# Uninstall and reinstall specific versions of libraries
!pip uninstall typer -y
!pip uninstall spacy -y
!pip uninstall weasel -y
!pip install typer==0.9.0
!pip install spacy==3.7.4
!pip install weasel==0.3.4
!pip install langchain
!pip install openai
!pip install tiktoken
!pip install faiss-gpu
!pip install langchain_experimental
!pip install "langchain[docarray]"
!pip install sentence_transformers
!pip install chromadb
!pip install InstructorEmbedding
!pip install fastapi
!pip install starlette
!pip install transformers
!pip install huggingface_hub
!pip install requests
!pip install beautifulsoup4

import os
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.schema import Document
import requests
from bs4 import BeautifulSoup
from transformers import AutoTokenizer, AutoModelForQuestionAnswering
from huggingface_hub import login
import torch

# Use your provided Hugging Face token
token = "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"

# Log in to Hugging Face
login(token=token, add_to_git_credential=True)

# Load the InLegalBERT model and tokenizer from Hugging Face
model_name = "law-ai/InLegalBERT"
qa_tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)
qa_model = AutoModelForQuestionAnswering.from_pretrained(model_name, token=token)

# Define the function to generate response
def generate_response(question, context):
    # Tokenize the question and context
    inputs = qa_tokenizer(question, context, return_tensors="pt", max_length=512, truncation=True)

    # Forward pass through the model
    outputs = qa_model(**inputs)

    # Retrieve the start and end logits
    start_logits = outputs.start_logits
    end_logits = outputs.end_logits

    # Find the best answer span
    answer_start = torch.argmax(start_logits)
    answer_end = torch.argmax(end_logits) + 1

    # Convert token indices to strings
    answer_tokens = inputs.input_ids[0][answer_start:answer_end]
    answer = qa_tokenizer.decode(answer_tokens)

    return answer

# Define the function to get vectorstore
def get_vectorstore(documents):
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vectorstore = Chroma.from_documents(
        documents=documents,
        embedding=embeddings,
        ids=None,
        collection_name="heart",
        persist_directory='./chroma_db'
    )
    vectorstore.persist()
    return vectorstore

# Define the function to fetch judiciary updates
def fetch_judiciary_updates(url):
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.content, 'html.parser')
        updates = soup.find_all('div', class_='title entry-title')  # Example selector
        return [update.text for update in updates]
    else:
        return []

# Define the function to search documents
def search_documents(query, vectorstore):
    search_results = vectorstore.similarity_search(query)
    if search_results:
        return search_results[0].page_content
    return "No relevant information found."

# Load data from files
rights_file_path = '/content/Rights of Prisoners in India.txt'
bail_procedure_file_path = '/content/Bail.txt'

def read_file_with_fallback(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return file.read()
    except UnicodeDecodeError:
        with open(file_path, 'r', encoding='latin1', errors='ignore') as file:
            return file.read()

rights_text = read_file_with_fallback(rights_file_path)
bail_procedure_text = read_file_with_fallback(bail_procedure_file_path)

# URL of the judiciary website
judiciary_url = 'https://blog.indiankanoon.org/2024/01/comprehensive-up-to-date-laws-from.html'

# Fetch the latest updates
latest_updates = fetch_judiciary_updates(judiciary_url)

# Combine static and dynamic data
combined_data = rights_text + "\n" + bail_procedure_text + "\n" + "\n".join(latest_updates)

# Create a list of Document objects
documents = [
    Document(page_content=rights_text, metadata={"source": "rights_file"}),
    Document(page_content=bail_procedure_text, metadata={"source": "bail_procedure_file"}),
    *[Document(page_content=update, metadata={"source": "judiciary_update"}) for update in latest_updates]
]

# Create and persist vectorstore
vectorstore = get_vectorstore(documents)

# Example query
query = "I was involved in an altercation where I accidentally caused serious injury to another person. I did not intend to harm them, and it was an unintentional act of self-defense. I have been charged with grievous hurt under Section 326 of the Indian Penal Code. This is my first offense, and I have no prior criminal record. Can I get bail in this situation? If yes, please explain the process for obtaining bail in such cases, including any conditions that might be imposed."
context = search_documents(query, vectorstore)
response = generate_response(query, context)
print("Response:", response)